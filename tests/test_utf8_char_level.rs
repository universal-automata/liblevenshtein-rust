use liblevenshtein::dictionary::double_array_trie_char::DoubleArrayTrieChar;
use liblevenshtein::prelude::*;

#[test]
fn test_unicode_empty_query_char_level() {
    println!("\n=== UTF-8 Char-Level: Empty Query â†’ Unicode Character ===\n");

    // This was failing with byte-level: "" â†’ "Â¡" required distance 2 (two bytes)
    // With char-level it should correctly be distance 1 (one character)
    let dict = DoubleArrayTrieChar::from_terms(vec!["Â¡"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    println!("Dictionary: [\"Â¡\"]");
    println!("Query: \"\" (empty)");
    println!("Max distance: 1");
    println!("Character 'Â¡': {:?}", 'Â¡');
    println!("Bytes: {:?} (length: {})", "Â¡".as_bytes(), "Â¡".len());
    println!(
        "Chars: {} (length: {})\n",
        "Â¡".chars().count(),
        "Â¡".chars().count()
    );

    let results: Vec<_> = transducer.query("", 1).collect();
    println!("Results: {:?}\n", results);

    assert!(
        results.contains(&"Â¡".to_string()),
        "Empty query should match \"Â¡\" at distance 1 (one character insertion)"
    );

    println!("âœ… SUCCESS: Char-level correctly treats \"Â¡\" as distance 1 from empty string");
}

#[test]
fn test_unicode_various_distances() {
    println!("\n=== UTF-8 Char-Level: Various Distances ===\n");

    let dict = DoubleArrayTrieChar::from_terms(vec!["Ã©", "Ã©e", "Ã©Ã©e"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    println!("Dictionary: [\"Ã©\", \"Ã©e\", \"Ã©Ã©e\"]");
    println!("Each 'Ã©' is 1 character (2 bytes in UTF-8)\n");

    for max_dist in 0..=3 {
        let results: Vec<_> = transducer.query("", max_dist).collect();
        println!("Empty query, max_distance={}: {:?}", max_dist, results);
    }

    // At distance 1: can insert 1 character â†’ should find "Ã©"
    let results_1: Vec<_> = transducer.query("", 1).collect();
    assert!(results_1.contains(&"Ã©".to_string()));
    assert!(!results_1.contains(&"Ã©e".to_string())); // requires 2 insertions

    // At distance 2: can insert 2 characters â†’ should find "Ã©" and "Ã©e"
    let results_2: Vec<_> = transducer.query("", 2).collect();
    assert!(results_2.contains(&"Ã©".to_string()));
    assert!(results_2.contains(&"Ã©e".to_string()));
    assert!(!results_2.contains(&"Ã©Ã©e".to_string())); // requires 3 insertions

    // At distance 3: should find all
    let results_3: Vec<_> = transducer.query("", 3).collect();
    assert!(results_3.contains(&"Ã©".to_string()));
    assert!(results_3.contains(&"Ã©e".to_string()));
    assert!(results_3.contains(&"Ã©Ã©e".to_string()));

    println!("\nâœ… SUCCESS: Character-level distances work correctly");
}

#[test]
fn test_emoji_distance() {
    println!("\n=== UTF-8 Char-Level: Emoji Distances ===\n");

    let dict = DoubleArrayTrieChar::from_terms(vec!["ğŸ‰", "helloğŸ‰", "ğŸ‰world"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    println!("Dictionary: [\"ğŸ‰\", \"helloğŸ‰\", \"ğŸ‰world\"]");
    println!("Emoji 'ğŸ‰' is 1 character (4 bytes in UTF-8)\n");

    // Empty query at distance 1 should find solo emoji
    let results: Vec<_> = transducer.query("", 1).collect();
    println!("Empty query at distance 1: {:?}", results);
    assert!(results.contains(&"ğŸ‰".to_string()));

    // Query "hello" at distance 1 should find "helloğŸ‰" (insert emoji at end)
    let results: Vec<_> = transducer.query("hello", 1).collect();
    println!("Query \"hello\" at distance 1: {:?}", results);
    assert!(results.contains(&"helloğŸ‰".to_string()));

    println!("\nâœ… SUCCESS: Emoji treated as single character");
}

#[test]
fn test_cjk_distance() {
    println!("\n=== UTF-8 Char-Level: CJK Character Distances ===\n");

    let dict = DoubleArrayTrieChar::from_terms(vec!["ä¸­", "ä¸­æ–‡", "ä¸­æ–‡å­—"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    println!("Dictionary: [\"ä¸­\", \"ä¸­æ–‡\", \"ä¸­æ–‡å­—\"]");
    println!("Each CJK character is 1 character (3 bytes in UTF-8)\n");

    // Empty query at distance 1: should find "ä¸­" (1 insertion)
    let results_1: Vec<_> = transducer.query("", 1).collect();
    println!("Distance 1: {:?}", results_1);
    assert!(results_1.contains(&"ä¸­".to_string()));

    // Empty query at distance 2: should find "ä¸­" and "ä¸­æ–‡" (2 insertions)
    let results_2: Vec<_> = transducer.query("", 2).collect();
    println!("Distance 2: {:?}", results_2);
    assert!(results_2.contains(&"ä¸­".to_string()));
    assert!(results_2.contains(&"ä¸­æ–‡".to_string()));

    // Query "ä¸­" at distance 1: should find "ä¸­æ–‡" (insert one char)
    let results: Vec<_> = transducer.query("ä¸­", 1).collect();
    println!("Query \"ä¸­\" at distance 1: {:?}", results);
    assert!(results.contains(&"ä¸­".to_string())); // exact match
    assert!(results.contains(&"ä¸­æ–‡".to_string())); // insert 'æ–‡'

    println!("\nâœ… SUCCESS: CJK characters treated correctly");
}

#[test]
fn test_mixed_unicode_query() {
    println!("\n=== UTF-8 Char-Level: Mixed Unicode Query ===\n");

    let dict =
        DoubleArrayTrieChar::from_terms(vec!["cafÃ©", "cafe", "naÃ¯ve", "naive", "rÃ©sumÃ©", "resume"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    println!("Dictionary contains accented and non-accented variants\n");

    // Query "cafe" should find "cafÃ©" at distance 1 (substitute eâ†’Ã©)
    let results: Vec<_> = transducer.query("cafe", 1).collect();
    println!("Query \"cafe\" at distance 1: {:?}", results);
    assert!(results.contains(&"cafe".to_string())); // exact
    assert!(results.contains(&"cafÃ©".to_string())); // one substitution

    // Query "cafÃ©" should find "cafe" at distance 1
    let results: Vec<_> = transducer.query("cafÃ©", 1).collect();
    println!("Query \"cafÃ©\" at distance 1: {:?}", results);
    assert!(results.contains(&"cafÃ©".to_string())); // exact
    assert!(results.contains(&"cafe".to_string())); // one substitution

    println!("\nâœ… SUCCESS: Accented characters are single character edits");
}

#[test]
fn test_transposition_with_unicode() {
    println!("\n=== UTF-8 Char-Level: Transposition with Unicode ===\n");

    let dict = DoubleArrayTrieChar::from_terms(vec!["cafÃ©", "Ã©fac"]);
    let transducer = Transducer::new(dict, Algorithm::Transposition);

    println!("Dictionary: [\"cafÃ©\", \"Ã©fac\"]");
    println!("Using Transposition algorithm\n");

    // Swap 'Ã©' and 'f' in "Ã©fac" â†’ "fÃ©ac"
    let results: Vec<_> = transducer.query("fÃ©ac", 1).collect();
    println!("Query \"fÃ©ac\" at distance 1: {:?}", results);

    // Should find "Ã©fac" via one transposition
    assert!(results.contains(&"Ã©fac".to_string()));

    println!("\nâœ… SUCCESS: Transposition works with Unicode characters");
}

#[test]
fn test_query_with_distance_unicode() {
    println!("\n=== UTF-8 Char-Level: Query with Distance (Unicode) ===\n");

    let dict = DoubleArrayTrieChar::from_terms(vec!["cafÃ©", "naÃ¯ve"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    // Query and get distances
    let results: Vec<_> = transducer.query_with_distance("cafe", 2).collect();

    println!("Query \"cafe\" at max_distance 2:");
    for candidate in &results {
        println!("  {}: distance {}", candidate.term, candidate.distance);
    }

    // Find "cafÃ©" - should be distance 1 (substitute eâ†’Ã©)
    let cafe_result = results.iter().find(|c| c.term == "cafÃ©");
    assert!(cafe_result.is_some());
    assert_eq!(cafe_result.unwrap().distance, 1);

    println!("\nâœ… SUCCESS: Distances correctly computed for Unicode");
}

#[test]
fn test_combining_characters() {
    println!("\n=== UTF-8 Char-Level: Combining Characters ===\n");

    // NOTE: "Ã©" can be represented as:
    // - NFC (composed): '\u{00E9}' - single code point
    // - NFD (decomposed): 'e' + '\u{0301}' (combining acute) - two code points

    // For this test, we use NFC (single character)
    let dict = DoubleArrayTrieChar::from_terms(vec!["cafÃ©"]); // NFC form
    let transducer = Transducer::new(dict, Algorithm::Standard);

    let results: Vec<_> = transducer.query("cafÃ©", 0).collect(); // exact match
    println!("Query \"cafÃ©\" (NFC) for exact match: {:?}", results);
    assert!(results.contains(&"cafÃ©".to_string()));

    println!("\nâœ… SUCCESS: NFC Unicode handled correctly");
    println!("Note: NFD (decomposed) would be treated as separate characters");
}

#[test]
fn test_grapheme_clusters_caveat() {
    println!("\n=== UTF-8 Char-Level: Grapheme Cluster Caveat ===\n");

    // CharUnit for char treats each Unicode scalar as one unit
    // But some "characters" are multiple scalars (grapheme clusters)
    // Example: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ (family emoji) is multiple code points joined with ZWJ

    let dict = DoubleArrayTrieChar::from_terms(vec!["hello"]);
    let transducer = Transducer::new(dict, Algorithm::Standard);

    // This works correctly for most Unicode
    let results: Vec<_> = transducer.query("hÃ©llo", 1).collect();
    assert!(results.contains(&"hello".to_string()));

    println!("âœ… Current implementation: Unicode scalar values (char)");
    println!("Limitation: Grapheme clusters (like family emoji) are multiple chars");
    println!("This is acceptable for most use cases\n");
}
