name: Nightly Tests and Benchmarks

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: write
  issues: write

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: full

jobs:
  nightly-matrix:
    name: Nightly Build & Test ${{ matrix.platform.name }}
    runs-on: ${{ matrix.platform.os }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        platform:
          - name: Linux x86_64
            os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            rustflags: "-C target-feature=+aes,+sse2"

          - name: macOS ARM64
            os: macos-latest
            target: aarch64-apple-darwin
            rustflags: "-C target-feature=+aes,+neon"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Install protobuf compiler (Linux)
        if: runner.os == 'Linux'
        run: sudo apt-get update && sudo apt-get install -y protobuf-compiler

      - name: Install protobuf compiler (macOS)
        if: runner.os == 'macOS'
        run: brew install protobuf

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: nightly
          target: ${{ matrix.platform.target }}

      - name: Build liblevenshtein
        env:
          RUSTFLAGS: ${{ matrix.platform.rustflags }}
        run: |
          echo "::group::Building liblevenshtein"
          cargo build --release --all-features --target ${{ matrix.platform.target }} --verbose
          echo "::endgroup::"

      - name: Run all tests
        env:
          RUSTFLAGS: ${{ matrix.platform.rustflags }}
        run: |
          echo "::group::Running all tests"
          cargo test --all-features --target ${{ matrix.platform.target }} --verbose -- --nocapture
          echo "::endgroup::"

      - name: Run benchmarks
        if: runner.os == 'Linux'
        env:
          RUSTFLAGS: ${{ matrix.platform.rustflags }}
        run: |
          echo "::group::Running benchmarks"
          cargo bench --all-features --target ${{ matrix.platform.target }} --no-fail-fast -- --output-format bencher | tee benchmark-results.txt
          echo "::endgroup::"

      - name: Parse and format benchmark results
        if: runner.os == 'Linux'
        run: |
          echo "## Benchmark Results - ${{ matrix.platform.name }}" > benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "| Benchmark | Time | Throughput |" >> benchmark-summary.md
          echo "|-----------|------|------------|" >> benchmark-summary.md

          # Parse bencher output format: test name ... bench: <time> ns/iter (+/- <variance>)
          grep "bench:" benchmark-results.txt | while read -r line; do
            # Extract benchmark name (everything before '...') and trim whitespace
            name=$(echo "$line" | sed 's/test \(.*\) \.\.\..*/\1/' | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')

            # Extract time and unit
            time=$(echo "$line" | grep -oP '[\d,]+ ns/iter' | head -1)

            # Calculate throughput if available
            if [[ "$time" =~ ([0-9,]+) ]]; then
              ns="${BASH_REMATCH[1]//,/}"
              if [ "$ns" -gt 0 ]; then
                ops_per_sec=$(( 1000000000 / ns ))
                # Format with thousand separators
                throughput=$(printf "%'d ops/s" $ops_per_sec)
              else
                throughput="-"
              fi
            else
              throughput="-"
            fi

            echo "| \`$name\` | $time | $throughput |" >> benchmark-summary.md
          done

          echo "" >> benchmark-summary.md
          echo "**Note:** Benchmarks are run on GitHub Actions runners and may vary." >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "Full results available in artifacts." >> benchmark-summary.md

      - name: Upload benchmark results
        if: runner.os == 'Linux'
        uses: actions/upload-artifact@v4
        with:
          name: nightly-benchmarks-${{ matrix.platform.name }}
          path: |
            benchmark-results.txt
            benchmark-summary.md
          retention-days: 30

      - name: Check for performance regressions
        if: runner.os == 'Linux' && failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸ”¥ Nightly Build Failed - ${{ matrix.platform.name }}',
              body: 'The nightly build has failed. Please investigate.\n\nWorkflow run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}',
              labels: ['nightly-failure', 'ci']
            })

  code-coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install protobuf compiler
        run: sudo apt-get update && sudo apt-get install -y protobuf-compiler

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: nightly
          components: llvm-tools-preview

      - name: Install cargo-llvm-cov
        run: cargo install cargo-llvm-cov

      - name: Generate code coverage
        env:
          RUSTFLAGS: "-C target-feature=+aes,+sse2"
        run: cargo llvm-cov --all-features --workspace --lcov --output-path lcov.info

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: lcov.info
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  dependency-audit:
    name: Security Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1

      - name: Install cargo-audit
        run: cargo install cargo-audit

      - name: Run security audit
        run: cargo audit

      - name: Check for outdated dependencies
        run: |
          cargo install cargo-outdated
          cargo outdated --exit-code 1 || echo "Some dependencies are outdated"

  nightly-summary:
    name: Nightly Summary
    runs-on: ubuntu-latest
    needs: [nightly-matrix, code-coverage, dependency-audit]
    if: always()

    steps:
    - name: Download benchmark results
      if: needs.nightly-matrix.result == 'success'
      uses: actions/download-artifact@v4
      with:
        pattern: nightly-benchmarks-*
        path: ./benchmark-results
        merge-multiple: true
      continue-on-error: true

    - name: Generate summary
      run: |
        echo "## Nightly Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Nightly Matrix | ${{ needs.nightly-matrix.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Code Coverage | ${{ needs.code-coverage.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Audit | ${{ needs.dependency-audit.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        if [ "${{ needs.nightly-matrix.result }}" == "success" ]; then
          echo "âœ… Nightly tests passed!" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ Nightly tests failed!" >> $GITHUB_STEP_SUMMARY
        fi

        echo "" >> $GITHUB_STEP_SUMMARY

        # Include benchmark summary if available
        if [ -f "./benchmark-results/benchmark-summary.md" ]; then
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat ./benchmark-results/benchmark-summary.md >> $GITHUB_STEP_SUMMARY
        fi
