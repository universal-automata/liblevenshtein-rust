# Universal Levenshtein Automata - Complete Documentation

**Last Updated**: 2025-11-11
**Status**: ‚úÖ **Implemented** - SmallVec-based Universal transducers (Standard + Transposition)
**Implementation**: src/transducer/universal/ (commit ce7ccca, 2025-11-11)

---

## Overview

This directory contains **complete documentation** of Universal Levenshtein Automata, including:

1. **Theoretical Foundations** - Complete analysis of Mitankin's 2005 thesis (77 pages)
2. **Implementation Planning** - Practical integration with liblevenshtein-rust
3. **Algorithm Details** - Full pseudocode and construction algorithms
4. **Cross-Reference Materials** - Bridging theory to practice

**Universal Levenshtein Automata** are parameter-free, deterministic finite automata that recognize the Levenshtein neighborhood L^œá_{Lev}(n, w) for **any word w** without modification. This directory covers both the core theory and planned extensions (restricted substitutions).

---

## Core Theory Documentation

### Primary Sources

**Core Thesis** (2005):
- **Title**: "Universal Levenshtein Automata - Building and Properties"
- **Author**: Petar Nikolaev Mitankin (Master's Thesis, Sofia University)
- **Supervisor**: Dr. Stoyan Mihov
- **Location**: `/home/dylon/Papers/Approximate String Matching/Universal Levenshtein Automata - Building and Properties/`
- **Pages**: 77 pages (split into pg_0001.pdf through pg_0077.pdf)
- **Status**: ‚úÖ **Fully documented** (2025-11-11)

**Extension Paper** (2009):
- **Title**: "Universal Levenshtein Automata for a Generalization of the Levenshtein Distance"
- **Authors**: Petar Mitankin, Stoyan Mihov, Klaus U. Schulz
- **Published**: Annuaire de l'Universit√© de Sofia "St. Kliment Ohridski", Tome 99, 2009, pages 5-23
- **Location**: `/home/dylon/Papers/Approximate String Matching/Universal Levenshtein Automata for a Generalization of the Levenshtein Distance.pdf`
- **Topic**: Restricted substitutions (implementation planning in progress)

### Complete Documentation Index

#### Theory Documents (Core Thesis 2005 + TCS Paper 2011)

1. **[PAPER_SUMMARY.md](./PAPER_SUMMARY.md)** (~2000 lines) ‚≠ê
   - Complete chapter-by-chapter analysis of 2005 thesis (all 77 pages)
   - Every definition, theorem, lemma, proposition with proofs
   - Section-by-section narrative flow
   - All examples worked through step-by-step
   - **Start here** for comprehensive understanding

2. **[TCS_2011_PAPER_ANALYSIS.md](./TCS_2011_PAPER_ANALYSIS.md)** (~3500 lines) ‚≠ê **NEW**
   - Complete analysis of 2011 TCS journal paper
   - **Generalized operation framework** beyond Levenshtein
   - **Bounded diagonal property** (Theorem 8.2) - validates SmallVec optimization
   - Matrix-state construction with extensors
   - Empirical evaluation: **2.77-5√ó speedup** over dynamic programming
   - **Critical bug identification**: Diagonal crossing fix needed
   - Enhancement opportunities and implementation roadmap
   - **Use this** for understanding theoretical foundations and optimization opportunities

3. **[TCS_2011_LAZY_APPLICABILITY.md](./TCS_2011_LAZY_APPLICABILITY.md)** (~800 lines) **NEW**
   - **Answers**: "Does TCS 2011 paper apply to lazy automata?" ‚Üí **PARTIAL**
   - What applies: Bounded diagonal, operations, subsumption ‚úÖ
   - What doesn't: Alphabet independence, word-agnostic states ‚ùå
   - **Why lazy-universal hybrid is impossible** (contradictory requirements)
   - Concrete benefits for lazy implementation
   - Priority recommendations with code examples
   - **Use this** to understand which concepts transfer to lazy vs universal

4. **[GLOSSARY.md](./GLOSSARY.md)** (~650 lines)
   - Complete notation reference for all symbols
   - Quick lookup table with 50+ symbols and page numbers
   - Organized by category (metasymbols, distances, positions, automata, functions)
   - Usage tips for reading paper and implementing
   - Common confusions explained
   - **Use this** while reading PAPER_SUMMARY.md or thesis

5. **[ALGORITHMS.md](./ALGORITHMS.md)** (~1500 lines)
   - Section 6 (Building Algorithms) fully extracted
   - Summarized and detailed pseudocode
   - Complete type definitions and API functions
   - All helper functions (Delta, Delta_E, Delta_E_D, etc.)
   - Complexity analysis with exact formulas
   - **Use this** for implementation reference

6. **[THEORETICAL_FOUNDATIONS.md](./THEORETICAL_FOUNDATIONS.md)** (~1400 lines)
   - All definitions, propositions, lemmas, theorems
   - Complete proofs and proof sketches
   - Organized by section (Distance Properties, NFAs, DFAs, Universal Automata, Minimality)
   - Cross-reference index
   - Critical warnings (triangle inequality violation!)
   - **Use this** for mathematical rigor

7. **[TCS_2011_IMPLEMENTATION_MAPPING.md](./TCS_2011_IMPLEMENTATION_MAPPING.md)** (~1200 lines) ‚≠ê **NEW**
   - Concrete mapping from TCS 2011 paper to code
   - Maps theoretical concepts to **both lazy and universal** implementations
   - Shows what applies to each architecture (9 major concepts analyzed)
   - File location reference table for quick navigation
   - Implementation status tracking (‚úÖ complete, üöß in progress, üêõ buggy, ‚ùå N/A)
   - Priority action items with specific file:line references
   - **Use this** when implementing paper concepts or understanding code structure

#### Implementation Planning Documents

See [Implementation Strategy](#implementation-strategy) section below for details on:
- **technical-analysis.md** - Current codebase analysis
- **use-cases.md** - Practical applications
- **implementation-plan.md** - Phase-by-phase roadmap
- **decision-matrix.md** - Approach comparison
- **architectural-sketches.md** - Code designs

#### Optimization Research Documents

**State Container Optimization** (2025-11-11):

6. **[UNIVERSAL_BTREESET_VS_SMALLVEC_RESULTS.md](./UNIVERSAL_BTREESET_VS_SMALLVEC_RESULTS.md)** (~1400 lines) ‚≠ê
   - Comprehensive benchmark analysis comparing BTreeSet vs SmallVec
   - 24 benchmark scenarios across Standard and Transposition algorithms
   - Performance results: SmallVec wins 75% with 1.08-2.06√ó speedup
   - Memory analysis: SmallVec uses 4.8√ó less memory for typical states
   - **Current implementation**: SmallVec (canonical approach as of commit ce7ccca)
   - **Use this** to understand state container design decisions

7. **[BTREESET_VS_SMALLVEC_COMPARISON.md](./BTREESET_VS_SMALLVEC_COMPARISON.md)** (~350 lines)
   - Initial comparison guide (pre-benchmarking)
   - Theoretical analysis of both approaches
   - Benchmarking methodology
   - **Historical**: See UNIVERSAL_BTREESET_VS_SMALLVEC_RESULTS.md for actual results

8. **[Archived: BTreeSet Implementation](../../archive/universal-levenshtein/btreeset-implementation/)**
   - Original BTreeSet implementation with error-based early termination
   - Archived with comprehensive documentation explaining why it was replaced
   - Historical reference for educational purposes
   - **Reason for archival**: Empirical benchmarking showed SmallVec superior

#### Phonetic Corrections Research (2025-11-12)

**Location**: [`docs/research/phonetic-corrections/`](../phonetic-corrections/)

9. **[ENGLISH_PHONETIC_FEASIBILITY.md](../phonetic-corrections/ENGLISH_PHONETIC_FEASIBILITY.md)** (~2100 lines) ‚≠ê **NEW**
   - Comprehensive analysis of English phonetic spelling rules from https://zompist.com/spell.html
   - Classification of ~50 phonetic rules by modelability with universal automata
   - **60-85% of rules are modelable** (45% fully, 34% partially, 21% not modelable)
   - Theoretical justification from TCS 2011 bounded diagonal property
   - 7 worked examples: telephone‚Üítel@f√∂n, daughter‚Üíd√≤t@r, right‚Üír√Øt, etc.
   - Required extensions: larger operations (d=3,4), position-aware, bi-directional context
   - Performance analysis: 5-10√ó speedup vs DP, 8-80 MB memory depending on operation set
   - Limitations: cannot model retroactive modifications, syllable boundaries, morphology
   - **Use this** to understand which English phonetic rules can be implemented with generalized operations

10. **[IMPLEMENTATION_GUIDE.md](../phonetic-corrections/IMPLEMENTATION_GUIDE.md)** (~1000 lines) ‚≠ê **NEW**
   - Practical step-by-step implementation guide for phonetic corrections
   - **3-phase approach**: Core (60-70% coverage), Extended (75-85%), Context (80-85%)
   - Complete Rust code examples for all operation types
   - Testing strategy with coverage measurement (CMU Pronouncing Dictionary)
   - Performance tuning and benchmarking guide
   - Integration examples: spell checker, fuzzy search, OCR post-processing
   - Estimated effort: Phase 1 (3-5 days), Phase 2 (2-3 weeks), Phase 3 (2-3 weeks)
   - **Use this** for implementing phonetic matching features in liblevenshtein-rust

**Phonetic Corrections Summary**:
- ‚úÖ **60-70%** fully modelable: consonant/vowel digraphs, silent letters, double consonants
- üü° **10-15%** partially modelable: context-dependent c/g softening, vowel-R interactions, complex GH patterns
- ‚ùå **15-25%** not modelable: retroactive vowel lengthening, syllable structure, morphological context
- **Practical applications**: Spell checking with phonetic suggestions, "sounds like" search, OCR correction
- **Performance**: 3-10√ó faster than DP for dictionary search, 75-85% word coverage
- **See also**: [Generalized Operations Design](../../design/generalized-operations.md#example-5-english-phonetic-corrections) for API usage

### Key Theoretical Contributions

From Mitankin's 2005 thesis:

1. **Parameter-Free Automaton**: A^{‚àÄ,œá}_n works for **any word length** without modification
2. **Three Distance Variants**:
   - œá = Œµ (standard Levenshtein)
   - œá = t (with transposition)
   - œá = ms (with merge/split)
3. **Bit Vector Encoding**: h_n(w, x) converts word pairs to bit vector sequences
4. **Universal Positions**: I + i#e and M + i#e with parameters I, M
5. **Subsumption Relation**: ‚â§^œá_s for state minimization
6. **Minimality Proof**: A^{‚àÄ,œá}_n has minimum states (Section 7)
7. **O(n¬≤) State Complexity**: Exact formulas and bounds (Section 6.3)

### Critical Warnings

‚ö†Ô∏è **Triangle Inequality Violation** (Page 3):
```
d^t_L does NOT satisfy the triangle inequality!
```

Counterexample: v="ac", w="ca", x="aa"
- d^t_L(v,x) = 2 > d^t_L(v,w) + d^t_L(w,x) = 1 + 1

**Implication**: Cannot use triangle inequality for pruning with transposition variant.

---

## Application: Restricted Substitutions

### What Problem Does It Solve?

Standard Levenshtein distance allows **any** character to be substituted for any other character. In practice, many applications have constraints:

- **Spell checkers**: Only keyboard-adjacent keys should substitute (e.g., 'a'‚Üî's' plausible, 'a'‚Üî'z' unlikely)
- **OCR correction**: Only visually similar characters should substitute (e.g., '1'‚Üî'I', 'O'‚Üî'0')
- **Phonetic matching**: Only sound-alike characters should substitute (e.g., 'f'‚Üî'ph', 's'‚Üî'c')
- **Handwriting recognition**: Only similar shapes should substitute

### The Solution: Restricted Substitutions

Instead of allowing **all** substitutions, define a set `S ‚äÜ Œ£ √ó Œ£` of **allowed** character pairs:

```
Standard Levenshtein:  Can substitute any (a,b)
Restricted (S):        Can substitute (a,b) only if (a,b) ‚àà S
```

**Example**:
```
Alphabet: {a, b, c, d, h, k, n, z}
Allowed:  S = {(a,d), (d,a), (h,k), (h,n)}

Query: "hahd"
Dict:  "hand"

‚úÖ Distance = 1  (h‚Üín substitution allowed, because (h,n) ‚àà S)

But if (h,n) ‚àâ S:
‚ùå Distance > 1  (would require delete 'h' + insert 'n')
```

This **improves precision** by rejecting unrealistic error patterns.

---

## Original Paper

**Title**: "Universal Levenshtein Automata for a Generalization of the Levenshtein Distance"

**Authors**: Petar Mitankin, Stoyan Mihov, Klaus U. Schulz
*(Same authors as your current Levenshtein automata implementation!)*

**Published**: Annuaire de l'Universit√© de Sofia "St. Kliment Ohridski", Tome 99, 2009, pages 5-23

**Location**: `/home/dylon/Papers/Approximate String Matching/Universal Levenshtein Automata for a Generalization of the Levenshtein Distance.pdf`

**Key Contributions**:
1. Extends universal Levenshtein automata to handle restricted substitutions
2. Maintains **deterministic** automaton property
3. Works with additional operations (transposition, merge, split)
4. Provides construction algorithm for universal automaton A_n^‚àÄ

---

## Documentation Index

### Analysis Documents
- **[technical-analysis.md](./technical-analysis.md)** - Current codebase analysis, gaps, integration points
- **[use-cases.md](./use-cases.md)** - Practical applications, example substitution sets, real-world scenarios

### Planning Documents
- **[implementation-plan.md](./implementation-plan.md)** - Phase-by-phase implementation (4 phases, 2-4 weeks)
- **[decision-matrix.md](./decision-matrix.md)** - Implementation approach comparison and recommendation
- **[architectural-sketches.md](./architectural-sketches.md)** - Code designs, trait definitions, struct layouts

### Tracking Documents
- **[progress-tracker.md](./progress-tracker.md)** - Task breakdown, status tracking, milestone monitoring

---

## Current Status

**Status**: ‚è≥ Research Phase - Not Yet Implemented

**Decision**: Pending approval of implementation approach

**Estimated Effort**: 2-4 weeks

**Implementation Phases**:
1. **Phase 1**: Core Restricted Substitutions (1-2 weeks)
2. **Phase 2**: Practical Use Cases (1 week)
3. **Phase 3**: Integration with Existing Algorithms (1 week)
4. **Phase 4**: Optimization (optional, 1 week)

---

## Quick Start

### For Researchers

1. **Understand the concept**:
   - Read this README for overview
   - Read [use-cases.md](./use-cases.md) for practical applications
   - Review the paper for algorithmic details

2. **Assess applicability**:
   - Check if your use case needs restricted substitutions
   - Compare with weighted distance (see [decision-matrix.md](./decision-matrix.md))

3. **Explore current architecture**:
   - Read [technical-analysis.md](./technical-analysis.md) for codebase details
   - Understand current Algorithm enum and transition logic

### For Implementers

1. **Review implementation plan**:
   - Read [implementation-plan.md](./implementation-plan.md) for phase breakdown
   - Check [architectural-sketches.md](./architectural-sketches.md) for code designs

2. **Select approach**:
   - Review [decision-matrix.md](./decision-matrix.md)
   - Consider Option A (New Algorithm Variant) vs Option B (Configuration)

3. **Track progress**:
   - Use [progress-tracker.md](./progress-tracker.md) for task management
   - Update status as tasks complete

---

## Key Concepts

### Restricted Substitutions (Set S)

**Definition** (from paper, Section 2):

The generalized distance `d_L^S(w, x)` is defined as the minimum number of operations to transform `w` into `x`, where:
- **Insert**: Add a character (cost = 1)
- **Delete**: Remove a character (cost = 1)
- **Substitute**: Replace character `a` with `b` **only if** `(a,b) ‚àà S` (cost = 1)

When `S = Œ£ √ó Œ£` (all pairs), this reduces to standard Levenshtein distance.

### Characteristic Vector Extension

**Standard Levenshtein**: Uses characteristic vector œá(a, w[i:j])
- Binary: 1 if character `a` appears at position, 0 otherwise

**Universal with S**: Uses S-characteristic vector œá_s(a, w[i:j])
- Binary: 1 if `(w[i], a) ‚àà S` (substitution allowed), 0 otherwise

This is the **key modification** needed in the codebase.

### Universal Automaton A_n^‚àÄ

The paper constructs a **universal automaton** `A_n^‚àÄ` that:
- Is **independent** of specific query/dictionary words
- Works for **any** error bound `n`
- Maintains **deterministic** property
- Can be combined with transposition, merge, and split operations

---

## What Universal LA Enables

### ‚úÖ Capabilities Added

1. **Keyboard-proximity constraints**
   - QWERTY layout: 'a' can substitute for 's', 'd', 'w', 'q', 'z'
   - AZERTY layout: Different adjacency rules
   - Dvorak layout: Yet another set of constraints

2. **OCR error modeling**
   - Visual similarity: '1' ‚Üî 'I' ‚Üî 'l', 'O' ‚Üî '0', 'S' ‚Üî '5'
   - Font-specific confusions
   - Context-aware restrictions

3. **Phonetic matching**
   - Sound-alike constraints: 'f' ‚Üî 'ph', 's' ‚Üî 'c', 'k' ‚Üî 'c'
   - Language-specific phonetic rules
   - Syllable-based restrictions

4. **Handwriting recognition**
   - Shape similarity: 'a' ‚Üî 'o', 'n' ‚Üî 'm', 'u' ‚Üî 'v'
   - Context-dependent confusions

5. **Script-based restrictions**
   - Block substitutions between Latin, Cyrillic, Greek scripts
   - Prevent impossible character confusions

6. **Combination with existing operations**
   - Restricted substitutions + Transposition
   - Restricted substitutions + MergeAndSplit

### ‚ùå Capabilities NOT Added

**Important limitations**:

1. **NOT weighted/variable costs**
   - All allowed operations still cost = 1
   - Restricted substitutions are **binary**: either allowed (cost=1) or blocked (cost=‚àû)
   - For continuous costs, see weighted Levenshtein distance (different approach)

2. **NOT arbitrary new operation types**
   - Paper covers: substitution, insertion, deletion, transposition, merge, split
   - Other operations would require extending the theory

3. **NOT non-deterministic automata**
   - Maintains determinism (critical for performance)

---

## Comparison: Universal LA vs Alternatives

| Feature | Universal LA | Weighted Distance | Standard LA (Current) |
|---------|-------------|-------------------|----------------------|
| **Restricted substitutions** | ‚úÖ Yes (binary) | ‚úÖ Yes (cost threshold) | ‚ùå No (all allowed) |
| **Variable operation costs** | ‚ùå No (uniform=1) | ‚úÖ Yes (continuous) | ‚ùå No (uniform=1) |
| **Keyboard proximity** | ‚úÖ Built-in | ‚ö†Ô∏è Via cost matrix | ‚ùå No |
| **OCR modeling** | ‚úÖ Built-in | ‚ö†Ô∏è Via cost matrix | ‚ùå No |
| **Phonetic rules** | ‚úÖ Built-in | ‚ö†Ô∏è Via cost matrix | ‚ùå No |
| **Deterministic** | ‚úÖ Yes | ‚ö†Ô∏è Complex | ‚úÖ Yes |
| **Implementation complexity** | üü° Moderate | üî¥ High | üü¢ Current |
| **Performance impact** | üü° ~10-20% overhead | üî¥ Significant | üü¢ Baseline |

**When to Use Each**:
- **Standard LA** (current): General fuzzy matching, no constraints
- **Universal LA**: Specific error patterns, binary restrictions (keyboard, OCR, phonetic)
- **Weighted Distance**: Continuous cost functions, character-specific weights

---

## Implementation Strategy

### Recommended Approach

**Option B: Configuration-Based** (Recommended)

Add substitution set as **optional configuration** rather than new Algorithm variant:

```rust
pub struct TransducerBuilder {
    algorithm: Algorithm,              // Existing: Standard, Transposition, MergeAndSplit
    substitution_set: Option<SubstitutionSet>,  // NEW: None = all allowed
}
```

**Advantages**:
- Works with all existing algorithms (Standard, Transposition, MergeAndSplit)
- Backward compatible (None = current behavior)
- Clean separation of concerns
- Flexible composition

**Alternative: Option A** (New Variant)

Add as 4th Algorithm variant:

```rust
pub enum Algorithm {
    Standard,
    Transposition,
    MergeAndSplit,
    RestrictedSubstitution,  // NEW
}
```

**Trade-offs**: See [decision-matrix.md](./decision-matrix.md) for detailed comparison.

---

## Key Requirements

### Critical Components Needed

1. ‚úÖ **SubstitutionSet structure**
   - Store allowed character pairs efficiently
   - Fast lookup (HashSet or perfect hashing)
   - Serialization support

2. ‚úÖ **S-characteristic vector**
   - Extend current œá implementation
   - Check `(query_char, dict_char) ‚àà S` for substitutions

3. ‚ö†Ô∏è **Modified transition functions**
   - transition.rs: Check substitution validity
   - Respect restricted substitutions in state computation

4. ‚ö†Ô∏è **Adjusted subsumption logic**
   - Paper notes: `d_L^S` may not satisfy triangle inequality
   - May need modified subsumption predicates

5. ‚úÖ **Builder API extensions**
   - `.with_substitution_set(set)` method
   - Predefined sets: keyboard layouts, phonetic rules, OCR rules

6. ‚úÖ **Preset substitution sets**
   - QWERTY keyboard
   - AZERTY keyboard
   - Dvorak keyboard
   - Common phonetic rules
   - OCR visual similarity

---

## Performance Expectations

### Expected Overhead

**Optimistic**: 5-10% slowdown (if substitution set lookups are fast)

**Realistic**: 10-20% slowdown (due to additional checks in transitions)

**Worst-case**: 30% slowdown (if substitution set is large and lookups are slow)

**Mitigation strategies**:
- Use HashSet for O(1) lookup
- Consider perfect hashing for static sets
- Cache lookup results in hot paths
- SIMD-friendly data structures

### When Is Overhead Worth It?

**High value**:
- Spell checkers (keyboard proximity critical)
- OCR systems (visual confusion sets)
- Phonetic search (sound-alike constraints)
- Handwriting recognition (shape similarity)

**Low value**:
- General fuzzy matching (no specific error patterns)
- Very small dictionaries (overhead dominates)
- Ultra-low latency requirements (every nanosecond counts)

---

## Related Documentation

### Library Documentation
- [Algorithm Layer](/docs/algorithms/02-levenshtein-automata/README.md) - Current automata implementation
- [Transducer Module](/src/transducer/mod.rs) - State machines and transitions
- [Position/State Tracking](/src/transducer/position.rs) - How positions are tracked

### Other Research
- [WallBreaker](/docs/research/wallbreaker/README.md) - Pattern splitting for large error bounds
- [GPU Acceleration](/docs/research/comparative-analysis/gpu-acceleration.md) - Performance analysis

### Code Locations
- `/src/transducer/algorithm.rs` - Algorithm enum (Standard, Transposition, MergeAndSplit)
- `/src/transducer/position.rs` - Position structure and subsumption logic
- `/src/transducer/transition.rs` - State transition functions
- `/src/transducer/builder.rs` - API for configuring fuzzy search

---

## Example: Keyboard-Proximity Spell Checker

```rust
use liblevenshtein::prelude::*;

// Define QWERTY keyboard adjacency
let mut qwerty = SubstitutionSet::new();

// Row 1: qwertyuiop
qwerty.add_bidirectional('q', 'w');
qwerty.add_bidirectional('w', 'e');
qwerty.add_bidirectional('w', 'q');
// ... (add all adjacent pairs)

// Row 2: asdfghjkl
qwerty.add_bidirectional('a', 's');
qwerty.add_bidirectional('a', 'w');  // diagonal adjacency
// ... (add all adjacent pairs)

// Build dictionary with restricted substitutions
let dict = TransducerBuilder::new()
    .algorithm(Algorithm::Standard)
    .with_substitution_set(qwerty)
    .build_from_iter(words);

// Query: "tesy" (typo for "test", 'y' adjacent to 't' on keyboard)
let results: Vec<_> = dict.fuzzy_search("tesy", 1).collect();
// ‚úÖ Returns: ["test"] - because 'y'‚Üî't' is keyboard-adjacent

// Query: "texz" (unlikely typo, 'x' not adjacent to 's')
let results: Vec<_> = dict.fuzzy_search("texz", 1).collect();
// ‚ùå Returns: [] or distant matches - because 'x'‚Üî's' not keyboard-adjacent
```

---

## Contact & Discussion

For questions or discussion about Universal Levenshtein Automata:
- Review documentation in this directory
- Check paper for algorithmic details
- Open GitHub issues for implementation questions

---

## License

Documentation follows Apache-2.0 license (same as main library).

---

**Last Updated**: 2025-11-06
**Status**: Research & Planning Phase
**Next Step**: Review documentation, select implementation approach, begin Phase 1
