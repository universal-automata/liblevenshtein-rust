# DynamicDawgChar Implementation

**Navigation**: [â† Dictionary Layer](../README.md) | [DynamicDawg (byte-level)](dynamic-dawg.md) | [Algorithms Home](../../README.md)

## Table of Contents

1. [Overview](#overview)
2. [Why Character-Level Matters](#why-character-level-matters)
3. [Unicode Support](#unicode-support)
4. [Data Structure](#data-structure)
5. [Key Differences from DynamicDawg](#key-differences-from-dynamicdawg)
6. [Union Operations](#union-operations)
7. [Usage Examples](#usage-examples)
8. [Performance Analysis](#performance-analysis)
9. [When to Use](#when-to-use)
10. [References](#references)

## Overview

`DynamicDawgChar` is a character-level variant of `DynamicDawg` designed for **correct Unicode handling** with **full dynamic update support**. While the byte-level variant treats text as sequences of bytes, the character-level variant operates on Unicode code points, providing accurate Levenshtein distances for multi-byte characters.

### Key Advantages

- âœ… **Correct Unicode distances**: Treats 'Ã©' as 1 character, not 2 bytes
- ğŸ”„ **Full dynamic updates**: Insert AND remove Unicode terms at runtime
- ğŸ”’ **Thread-safe**: Safe for concurrent reads and exclusive writes
- ğŸŒ **Full Unicode support**: CJK, emoji, accents, all scripts
- ğŸ’¾ **Space-efficient**: Shares common suffixes (20-40% reduction)

### When to Use

âœ… **Use DynamicDawgChar when:**
- Working with non-ASCII text (accented characters, CJK, emoji)
- Need both insert AND remove operations
- Correctness of Levenshtein distances matters
- Multi-language applications with evolving vocabularies
- Real-time collaborative editing with Unicode

âš ï¸ **Consider alternatives when:**
- ASCII-only text â†’ Use `DynamicDawg` (slightly faster)
- Static or append-only â†’ Use `DoubleArrayTrieChar` (3x faster)
- Maximum performance needed â†’ Use `DoubleArrayTrieChar`

## Why Character-Level Matters

### The UTF-8 Problem with Dynamic Dictionaries

Consider a user dictionary that evolves:
- User adds: "cafÃ©", "naÃ¯ve", "rÃ©sumÃ©"
- User removes: "cafe" (without accent)

With byte-level (`DynamicDawg`):
```
Insert "cafÃ©":
  'c' â†’ 'a' â†’ 'f' â†’ 0xC3 â†’ 0xA9 (final)
  âŒ 5 nodes for 4-character word

Insert "naÃ¯ve":
  'n' â†’ 'a' â†’ 0xC3 â†’ 0xAF â†’ 'v' â†’ 'e' (final)
  âŒ 6 nodes for 5-character word

Fuzzy search "cafe" (distance 1):
  âŒ Won't find "cafÃ©" (actually distance 2 in byte-level)
```

With character-level (`DynamicDawgChar`):
```
Insert "cafÃ©":
  'c' â†’ 'a' â†’ 'f' â†’ 'Ã©' (final)
  âœ… 4 nodes for 4-character word

Insert "naÃ¯ve":
  'n' â†’ 'a' â†’ 'Ã¯' â†’ 'v' â†’ 'e' (final)
  âœ… 5 nodes for 5-character word

Fuzzy search "cafe" (distance 1):
  âœ… Finds "cafÃ©" (distance 1: substitute eâ†’Ã©)
```

### Real-World Impact

**Example: Multi-language Spell Checker**

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::levenshtein::Algorithm;
use liblevenshtein::levenshtein_automaton::LevenshteinAutomaton;

let dict = DynamicDawgChar::new();

// User adds words from different languages
dict.insert("cafÃ©");     // French
dict.insert("naÃ¯ve");    // French
dict.insert("aÃ±o");      // Spanish
dict.insert("ä¸­æ–‡");     // Chinese
dict.insert("ğŸ˜€");       // Emoji

// Fuzzy search with typo
let automaton = LevenshteinAutomaton::new("cafe", 1, Algorithm::Standard);
let results: Vec<String> = automaton.query(&dict).collect();

println!("{:?}", results);
// Output: ["cafÃ©"] (âœ… correct character-level distance)

// Byte-level would give distance 2 or not find it
```

## Unicode Support

### Code Points vs Bytes

**DynamicDawgChar operates on Unicode scalar values (`char`)**:

```
Character â”‚ Code Point â”‚ UTF-8 Bytes       â”‚ Nodes in DAWG
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
'A'       â”‚ U+0041     â”‚ 0x41              â”‚ 1 (char-level)
'Ã©'       â”‚ U+00E9     â”‚ 0xC3 0xA9         â”‚ 1 (char-level)
'ä¸­'      â”‚ U+4E2D     â”‚ 0xE4 0xB8 0xAD    â”‚ 1 (char-level)
'ğŸ‰'      â”‚ U+1F389    â”‚ 0xF0 0x9F 0x8E 0x89â”‚ 1 (char-level)
```

### Supported Unicode Features

âœ… **Basic Multilingual Plane (BMP)**: All common languages
âœ… **Supplementary Planes**: Emoji, historic scripts, mathematical symbols
âœ… **Combining Characters**: Accents, diacritics (as separate code points)
âœ… **Right-to-Left**: Arabic, Hebrew
âœ… **CJK**: Chinese, Japanese, Korean characters

âš ï¸ **Note**: Operates on code points, not grapheme clusters. For grapheme-level handling, normalize input first.

## Data Structure

### Core Components

```rust
pub struct DynamicDawgChar<V: DictionaryValue = ()> {
    inner: Arc<RwLock<DynamicDawgCharInner<V>>>,
}

struct DynamicDawgCharInner<V: DictionaryValue> {
    nodes: Vec<DawgNodeChar<V>>,           // Node storage
    term_count: usize,                     // Number of terms
    needs_compaction: bool,                // Deletion flag
    suffix_cache: FxHashMap<u64, usize>,   // Hash â†’ node index
    bloom_filter: Option<BloomFilter>,     // Fast negative lookups
    auto_minimize_threshold: f32,          // Lazy minimization trigger
}

struct DawgNodeChar<V: DictionaryValue> {
    edges: SmallVec<[(char, usize); 4]>,  // Character â†’ child index
    is_final: bool,                        // Marks valid term
    ref_count: usize,                      // For safe deletion
    value: Option<V>,                      // Associated value
}
```

### Memory Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Component       â”‚ Size        â”‚ Per Node       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SmallVec edges  â”‚ Inline â‰¤4   â”‚ ~40 bytes*     â”‚
â”‚ is_final        â”‚ 1 byte      â”‚ 1 byte         â”‚
â”‚ ref_count       â”‚ 8 bytes     â”‚ 8 bytes        â”‚
â”‚ value (Option)  â”‚ V or 1 byte â”‚ Varies         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total per node  â”‚ ~49+ bytes  â”‚ ~49 bytes      â”‚
â”‚ Overhead        â”‚ Arc+RwLock  â”‚ 16 bytes total â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

*char is 4 bytes, so 4 edges = 4Ã—(4+8) = 48 bytes inline

**Comparison with DynamicDawg**:
- DynamicDawg: ~25 bytes/node
- DynamicDawgChar: ~49 bytes/node (2x more)

**Reason**: char (4 bytes) vs u8 (1 byte) for edge labels

### Clone Behavior & Memory Semantics

`DynamicDawgChar` uses `Arc<RwLock<...>>` internally, making `.clone()` a **shallow copy** that shares all underlying data structures between clones. The clone behavior is **identical** to `DynamicDawg` - only the edge label types differ (char vs u8).

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

let dict1 = DynamicDawgChar::from_iter(vec!["cafÃ©", "naÃ¯ve"]);
let dict2 = dict1.clone();  // O(1) - only increments Arc refcount

// Both dict1 and dict2 point to the SAME underlying data
dict1.insert("rÃ©sumÃ©");
assert!(dict2.contains("rÃ©sumÃ©"));  // âœ… Mutations visible through dict2!

// Term count reflects changes made via either clone
assert_eq!(dict1.len(), Some(3));
assert_eq!(dict2.len(), Some(3));  // Same count
```

#### Characteristics

| Property | Behavior | Impact |
|----------|----------|--------|
| **Time Complexity** | O(1) | Single atomic increment |
| **Space Complexity** | O(1) | ~16 bytes (Arc pointer only) |
| **Data Sharing** | âœ… Complete | All clones share same node graph |
| **Mutation Visibility** | âœ… Global | Changes via any clone affect all |
| **Thread Safety** | âœ… RwLock | Multiple readers OR single writer |
| **Independence** | âŒ None | No isolation between clones |

#### Unicode Considerations

Clone behavior is **independent of Unicode complexity**. Whether working with ASCII, multi-byte characters, emoji, or combining diacritics, the clone operation remains O(1):

```rust
// Simple ASCII
let dict1 = DynamicDawgChar::from_iter(vec!["hello"]);
let dict2 = dict1.clone();  // O(1)

// Multi-byte characters (CJK)
let dict3 = DynamicDawgChar::from_iter(vec!["æ—¥æœ¬", "æ±äº¬"]);
let dict4 = dict3.clone();  // Still O(1) - no character iteration

// Emoji (4-byte characters)
let dict5 = DynamicDawgChar::from_iter(vec!["ğŸ‘‹", "ğŸ‰"]);
let dict6 = dict5.clone();  // Still O(1)
```

**Why?** Clone only increments Arc's reference counter - it never traverses terms or characters.

#### When to Use Cloning

âœ… **Good use cases:**

1. **Multi-threaded Unicode processing:**
   ```rust
   use std::thread;

   let dict = DynamicDawgChar::from_iter(vec!["cafÃ©", "naÃ¯ve", "Ã¼ber"]);

   let handles: Vec<_> = (0..4).map(|_| {
       let dict_clone = dict.clone();
       thread::spawn(move || {
           dict_clone.contains("cafÃ©")  // Safe concurrent access
       })
   }).collect();
   ```

2. **International text processing:**
   ```rust
   let multilingual_dict = DynamicDawgChar::from_iter(vec![
       "hello",   // English
       "ã“ã‚“ã«ã¡ã¯", // Japanese
       "Ù…Ø±Ø­Ø¨Ø§",   // Arabic
       "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚",  // Russian
   ]);

   // Share across processing pipelines
   let pipeline1 = multilingual_dict.clone();
   let pipeline2 = multilingual_dict.clone();
   ```

âŒ **Bad use cases (common mistakes):**

1. **Expecting independent copies for different character sets:**
   ```rust
   let dict1 = DynamicDawgChar::from_iter(vec!["cafÃ©"]);
   let dict2 = dict1.clone();  // âŒ Still shares data!

   dict1.insert("naÃ¯ve");
   // dict2 also contains "naÃ¯ve" - clone doesn't isolate character sets
   ```

2. **Creating language-specific snapshots:**
   ```rust
   let dict = DynamicDawgChar::from_iter(vec!["hello", "world"]);
   let english_snapshot = dict.clone();  // âŒ NOT a snapshot!

   dict.insert("ã“ã‚“ã«ã¡ã¯");  // Add Japanese
   // "english_snapshot" now also contains Japanese - not isolated
   ```

#### Alternative: True Independence

For **independent copies** with Unicode data:

**Option 1: Serialize/Deserialize**
```rust
use serde::{Serialize, Deserialize};

// Works with all Unicode data
let bytes = bincode::serialize(&dict1)?;
let dict2: DynamicDawgChar = bincode::deserialize(&bytes)?;

dict1.insert("æ–°ã—ã„");  // Japanese: "new"
assert!(!dict2.contains("æ–°ã—ã„"));  // âœ… Independent
```

**Option 2: Rebuild from terms**
```rust
// Extract all Unicode terms
let terms: Vec<String> = dict1.iter().collect();

// Build new independent dictionary
let dict2 = DynamicDawgChar::from_iter(terms);
```

**Unicode-specific cost considerations:**

| Method | Time | Space | Notes |
|--------|------|-------|-------|
| `.clone()` | O(1) | O(1) | Regardless of character encoding |
| Serialize/Deserialize | O(n) | O(n) | Includes Unicode normalization overhead |
| Rebuild from terms | O(nÂ·m) | O(n) | m = average chars per term (not bytes!) |

**Important:** Rebuilding from terms with DynamicDawgChar is faster than DynamicDawg for the same visual length because it operates on character boundaries, not byte boundaries.

#### Comparison with Byte-Level DynamicDawg

| Aspect | DynamicDawg (byte) | DynamicDawgChar (char) |
|--------|-------------------|------------------------|
| **Clone type** | Shallow (Arc) | Shallow (Arc) - **identical** |
| **Clone cost** | O(1) | O(1) - **identical** |
| **Data sharing** | âœ… Yes | âœ… Yes - **identical** |
| **Memory per node** | ~25 bytes | ~49 bytes (char vs u8 labels) |
| **Use case** | ASCII, raw bytes | Unicode, multi-language |

**Key insight:** Clone behavior is **architecturally identical** - the char vs u8 difference only affects node storage, not ownership semantics.

#### Thread Safety with Unicode

Unicode processing adds no additional complexity to thread safety:

```rust
use std::thread;

let dict = DynamicDawgChar::from_iter(vec!["cafÃ©", "æ—¥æœ¬"]);

// Concurrent readers (safe for any Unicode data)
let readers: Vec<_> = (0..10).map(|i| {
    let dict = dict.clone();
    thread::spawn(move || {
        dict.contains("cafÃ©")  // Unicode comparison still thread-safe
    })
}).collect();

// Single writer
let writer = {
    let dict = dict.clone();
    thread::spawn(move || {
        dict.insert("æ–°ã—ã„èª")  // Unicode insertion still exclusive
    })
};
```

**RwLock guarantees remain the same:**
- Multiple concurrent readers (fast)
- Single exclusive writer (blocks readers)
- No data races regardless of character encoding

#### Summary

**Key Takeaways:**
1. ğŸ”— Clone behavior is **identical** to byte-level DynamicDawg
2. ğŸš€ **O(1)** regardless of Unicode complexity (ASCII, CJK, emoji, etc.)
3. ğŸ”„ **Mutations visible** across all clones for all character types
4. ğŸŒ **Unicode-safe** thread synchronization through RwLock
5. ğŸ“Š For **independence**, use serialization or rebuild (same as byte-level)

## Key Differences from DynamicDawg

### 1. Edge Labels

```rust
// DynamicDawg (byte-level)
edges: SmallVec<[(u8, usize); 4]>

// DynamicDawgChar (character-level)
edges: SmallVec<[(char, usize); 4]>
```

### 2. Input Processing

```rust
// DynamicDawg
fn insert(&self, term: &str) {
    let bytes = term.bytes();  // Iterate over bytes
    // ...
}

// DynamicDawgChar
fn insert(&self, term: &str) {
    let chars = term.chars();  // Iterate over characters
    // ...
}
```

### 3. Memory Usage

```
10,000-term dictionary (mixed scripts):

DynamicDawg (byte-level):
  Nodes: ~250KB
  Total: ~294KB

DynamicDawgChar (character-level):
  Nodes: ~490KB (2x more)
  Total: ~534KB
```

### 4. Performance

```
Operation times (10,000 terms):

                    DynamicDawg    DynamicDawgChar    Difference
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Construction        4.1ms          4.4ms              +7%
Insert (single)     800ns          840ns              +5%
Remove (single)     1.2Âµs          1.3Âµs              +8%
Contains (positive) 450ns          470ns              +4%
Fuzzy search (d=2)  42.3Âµs         44.7Âµs             +6%
```

**Insight**: ~5-8% overhead for correct Unicode handling - very reasonable!

## Union Operations

### Overview

The `union_with()` and `union_replace()` methods enable **merging two DynamicDawgChar dictionaries** with custom value combination logic, while maintaining **correct Unicode character semantics**. Essential for:

- ğŸŒ Merging multilingual dictionaries
- ğŸ“Š Aggregating statistics across Unicode text collections
- ğŸ”„ Combining user-specific and system-wide internationalized dictionaries
- ğŸ—‚ï¸ Building composite symbol tables with non-ASCII identifiers

**Key Characteristics**:
- ğŸ”’ **Thread-safe**: Operations use RwLock for concurrent access
- ğŸ’¾ **DAWG-preserving**: Maintains minimization through `insert_with_value()`
- ğŸŒ **Unicode-correct**: Operates on `char` (Unicode code points), not bytes
- âš¡ **Efficient**: O(nÂ·m) traversal with minimal memory overhead
- ğŸ¯ **Flexible**: Custom merge functions for value conflicts

### union_with() - Merge with Custom Logic

Combines two character-level dictionaries by inserting all terms from the source dictionary, applying a custom merge function when values conflict.

**Signature**:
```rust
fn union_with<F>(&self, other: &Self, merge_fn: F) -> usize
where
    F: Fn(&Self::Value, &Self::Value) -> Self::Value,
    Self::Value: Clone
```

**Parameters**:
- `other`: Source dictionary to merge from
- `merge_fn`: Function `(existing_value, new_value) -> merged_value` for conflicts
- **Returns**: Number of terms processed from `other`

**Algorithm**: Depth-First Search (DFS) on character edges
1. Initialize stack with root node `(node_idx=0, path=Vec<char>::new())`
2. Pop `(node_idx, path)` from stack
3. If node is final:
   - Convert `Vec<char>` path to `String` via iterator collection
   - Check if term exists in `self`
   - If exists: Apply `merge_fn` and update
   - If new: Insert with original value
4. Push all children onto stack (reversed for consistent ordering)
5. Repeat until stack empty

**Character vs Byte Difference**:
- `DynamicDawg`: Accumulates bytes (`Vec<u8>`), converts via `from_utf8()`
- `DynamicDawgChar`: Accumulates chars (`Vec<char>`), converts via `path.iter().collect()`
- Result: Proper handling of multi-byte Unicode sequences (emoji, diacritics, etc.)

**Complexity**:
- **Time**: O(nÂ·m) where n = terms in `other`, m = average term length **in characters**
  - O(nÂ·m) for DFS traversal
  - O(m) per term for `insert_with_value()`
- **Space**: O(d) where d = maximum trie depth (characters, not bytes)
  - DFS stack size proportional to deepest path
  - Constant additional memory

### Example 1: Multilingual Word Counts

Merge term frequencies across dictionaries with Unicode text:

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MutableMappedDictionary;

// French dictionary: word frequencies
let dict1: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict1.insert_with_value("cafÃ©", 10);        // Ã© = U+00E9 (2 bytes)
dict1.insert_with_value("naÃ¯ve", 5);        // Ã¯ = U+00EF (2 bytes)
dict1.insert_with_value("rÃ©sumÃ©", 3);       // Ã© appears twice

// More French text frequencies
let dict2: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict2.insert_with_value("cafÃ©", 7);         // Overlap
dict2.insert_with_value("crÃªpe", 4);        // Ãª = U+00EA (2 bytes)

// Merge by summing counts
let processed = dict1.union_with(&dict2, |left, right| left + right);

// Results: proper character counting
// - cafÃ©: 17 (10 + 7) - 4 characters, not 5 bytes
// - naÃ¯ve: 5 (unchanged)
// - rÃ©sumÃ©: 3 (unchanged)
// - crÃªpe: 4 (new)
assert_eq!(dict1.get_value("cafÃ©"), Some(17));
assert_eq!(dict1.get_value("crÃªpe"), Some(4));
assert_eq!(processed, 2); // Processed 2 terms from dict2
```

### Example 2: Emoji and Symbol Dictionaries

Demonstrates correct handling of 4-byte Unicode characters:

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MutableMappedDictionary;

// Dictionary 1: emoji usage counts
let dict1: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict1.insert_with_value("helloğŸ‘‹", 10);      // ğŸ‘‹ = U+1F44B (4 bytes)
dict1.insert_with_value("partyğŸ‰", 5);       // ğŸ‰ = U+1F389 (4 bytes)

// Dictionary 2: more emoji usage
let dict2: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict2.insert_with_value("helloğŸ‘‹", 3);       // Overlap
dict2.insert_with_value("rocketğŸš€", 7);      // ğŸš€ = U+1F680 (4 bytes)

dict1.union_with(&dict2, |left, right| left + right);

// Each emoji counts as ONE character, not 4 bytes
// - helloğŸ‘‹: 13 (10 + 3) - 6 chars: h,e,l,l,o,ğŸ‘‹
// - partyğŸ‰: 5
// - rocketğŸš€: 7
assert_eq!(dict1.get_value("helloğŸ‘‹"), Some(13));
assert_eq!(dict1.get_value("rocketğŸš€"), Some(7));
```

### Example 3: CJK (Chinese/Japanese/Korean) Text

Proper handling of East Asian characters:

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MutableMappedDictionary;

// Japanese dictionary
let dict1: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict1.insert_with_value("æ—¥æœ¬", 10);        // Nihon (Japan) - 2 chars
dict1.insert_with_value("æ±äº¬", 8);         // TÅkyÅ (Tokyo) - 2 chars

// More Japanese terms
let dict2: DynamicDawgChar<u32> = DynamicDawgChar::new();
dict2.insert_with_value("æ—¥æœ¬", 5);         // Overlap
dict2.insert_with_value("å¤§é˜ª", 6);         // ÅŒsaka (Osaka) - 2 chars

dict1.union_with(&dict2, |left, right| left + right);

// Each kanji = 1 character (3 bytes in UTF-8)
// - æ—¥æœ¬: 15 (10 + 5)
// - æ±äº¬: 8
// - å¤§é˜ª: 6
assert_eq!(dict1.get_value("æ—¥æœ¬"), Some(15));
assert_eq!(dict1.get_value("å¤§é˜ª"), Some(6));
```

### Example 4: Combining Diacritics

Demonstrates proper handling of combining characters vs precomposed:

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MutableMappedDictionary;

let dict1: DynamicDawgChar<Vec<String>> = DynamicDawgChar::new();

// Precomposed: Ã© = U+00E9 (single char)
dict1.insert_with_value("cafÃ©", vec!["french".to_string()]);

let dict2: DynamicDawgChar<Vec<String>> = DynamicDawgChar::new();

// Combining: e + Â´ = U+0065 + U+0301 (two chars)
// NOTE: "cafÃ©" with combining accent is different from precomposed "cafÃ©"
dict2.insert_with_value("cafÃ©", vec!["coffee_shop".to_string()]);

// Merge by concatenating lists
dict1.union_with(&dict2, |left, right| {
    let mut merged = left.clone();
    merged.extend(right.clone());
    merged
});

// Precomposed vs combining treated as DIFFERENT terms (Unicode normalization not performed)
assert_eq!(dict1.len().unwrap(), 2); // Two distinct entries
```

### union_replace() - Keep Right Values

Convenience method equivalent to `union_with(other, |_, right| right.clone())`.

**Signature**:
```rust
fn union_replace(&self, other: &Self) -> usize
where
    Self::Value: Clone
```

**Example with Unicode**:
```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MutableMappedDictionary;

let dict1: DynamicDawgChar<&str> = DynamicDawgChar::new();
dict1.insert_with_value("ZÃ¼rich", "city_old");      // Ã¼ = U+00FC
dict1.insert_with_value("MÃ¼nchen", "city_stable");  // Ã¼ = U+00FC

let dict2: DynamicDawgChar<&str> = DynamicDawgChar::new();
dict2.insert_with_value("ZÃ¼rich", "city_new");      // Override
dict2.insert_with_value("KÃ¶ln", "city_added");      // Ã¶ = U+00F6

// Replace conflicting values
dict1.union_replace(&dict2);

// - ZÃ¼rich: "city_new" (replaced)
// - MÃ¼nchen: "city_stable" (unchanged)
// - KÃ¶ln: "city_added" (new)
assert_eq!(dict1.get_value("ZÃ¼rich"), Some("city_new"));
assert_eq!(dict1.get_value("MÃ¼nchen"), Some("city_stable"));
assert_eq!(dict1.get_value("KÃ¶ln"), Some("city_added"));
```

### Implementation Details

The union operation uses **iterative depth-first search** on character-labeled edges:

```rust
// Simplified pseudocode
fn union_with<F>(&self, other: &Self, merge_fn: F) -> usize {
    let other_inner = other.inner.read();
    let mut processed = 0;

    // Initialize DFS with root: (node_index, accumulated_char_path)
    let mut stack: Vec<(usize, Vec<char>)> = vec![(0, Vec::new())];

    while let Some((node_idx, path)) = stack.pop() {
        let node = &other_inner.nodes[node_idx];

        // Process final nodes (complete terms)
        if node.is_final {
            // Convert Vec<char> to String
            let term: String = path.iter().collect();
            processed += 1;

            if let Some(other_value) = &node.value {
                if let Some(self_value) = self.get_value(&term) {
                    // Term exists - merge values
                    let merged = merge_fn(&self_value, other_value);
                    self.insert_with_value(&term, merged);
                } else {
                    // New term - insert directly
                    self.insert_with_value(&term, other_value.clone());
                }
            }
        }

        // Push children onto stack (char edges, not byte edges)
        for &(label_char, target_idx) in node.edges.iter().rev() {
            let mut child_path = path.clone();
            child_path.push(label_char);  // Push char, not byte
            stack.push((target_idx, child_path));
        }
    }

    processed
}
```

**Character-Level Specifics**:

1. **Edge labels are `char`**, not `u8`:
   - Each edge represents a Unicode code point
   - Multi-byte UTF-8 sequences stored as single `char`
   - Example: 'Ã©' (U+00E9) is one `char`, stored as one edge

2. **Path accumulation uses `Vec<char>`**:
   - No UTF-8 validation needed during traversal
   - Conversion to `String` is infallible: `path.iter().collect()`
   - Contrast with byte-level: `from_utf8(&path)` can fail

3. **Memory per stack frame**:
   - Byte-level: 16 bytes (`usize` + pointer to `Vec<u8>`)
   - Char-level: 16 bytes (same, but `Vec<char>` instead)
   - Char storage: 4 bytes per character (vs 1-4 bytes for UTF-8)

**Why Use `insert_with_value()`?**

Same rationale as byte-level variant:
1. **Preserves DAWG minimization**: Suffix sharing and node deduplication
2. **Maintains reference counts**: Proper accounting for shared nodes
3. **Simpler and safer**: Avoids complex graph manipulation bugs
4. **Unicode-correct**: Insertion handles char-to-internal encoding

### Performance Characteristics

| Operation | Time Complexity | Space Complexity | Typical Performance (10K terms) |
|-----------|----------------|------------------|--------------------------------|
| `union_with()` | O(nÂ·m) | O(d) | ~52ms |
| `union_replace()` | O(nÂ·m) | O(d) | ~52ms |
| DFS traversal | O(n) | O(d) | ~22ms |
| Per-term insertion | O(m) | O(1) amortized | ~2-6Âµs |

**Variables**:
- n = number of terms in source dictionary
- m = average term length **in characters** (not bytes)
- d = maximum trie depth in characters (typically 20-50)

**Character vs Byte Performance**:
```
Overhead: ~5-8% slower than byte-level variant
Reason: 4-byte char storage vs 1-4 byte UTF-8 encoding
Benefit: Correct Unicode distance calculations
```

**Benchmark Results** (AMD Ryzen 9 5950X, Unicode text):

| Dictionary Size | union_with() | Throughput |
|----------------|-------------|------------|
| 1,000 terms    | 4.5ms       | 222K terms/s |
| 10,000 terms   | 52ms        | 192K terms/s |
| 100,000 terms  | 560ms       | 179K terms/s |

*Note*: Benchmarks with mixed ASCII and multi-byte Unicode characters (average: 6 chars/term, 9 bytes/term).

### When to Use Union Operations

âœ… **Use `union_with()` when:**
- Merging multilingual dictionaries (internationalized applications)
- Aggregating statistics from Unicode text (emoji usage, CJK text analysis)
- Combining user-specific and system internationalized dictionaries
- Building symbol tables with non-ASCII identifiers (e.g., Greek letters in math)
- Processing natural language text requiring accurate character distances

âœ… **Use `union_replace()` when:**
- Updating multilingual dictionaries with newer translations
- Applying localized configuration overrides
- Synchronizing user dictionaries across Unicode-aware systems

âš ï¸ **Consider byte-level DynamicDawg when:**
- Text is ASCII-only (no multi-byte characters)
- Byte-level Levenshtein distance is acceptable
- Performance is critical and Unicode correctness is not required

âš ï¸ **Consider alternatives when:**
- **Unicode normalization needed**: Pre-normalize with `unicode-normalization` crate before insertion
- **Grapheme clusters required**: Use `unicode-segmentation` for proper grapheme handling
- **Dictionaries are static**: Pre-merge at build time

### Unicode Normalization Considerations

**Important**: Union operations do **not perform Unicode normalization**. Precomposed and combining characters are treated as distinct:

```rust
// These are DIFFERENT terms:
let precomposed = "cafÃ©";        // Ã© = U+00E9 (NFC)
let combining = "cafÃ©";          // e + Â´ = U+0065 + U+0301 (NFD)

// They will NOT merge even though they display identically
```

**Recommendation**: Normalize all terms to NFC or NFD before insertion:

```rust
use unicode_normalization::UnicodeNormalization;

let term = "cafÃ©".nfc().collect::<String>();
dict.insert_with_value(&term, value);
```

## Usage Examples

### Example 1: Basic Unicode Dictionary

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

let dict = DynamicDawgChar::new();

// Insert Unicode terms
dict.insert("cafÃ©");
dict.insert("naÃ¯ve");
dict.insert("ä¸­æ–‡");
dict.insert("æ—¥æœ¬èª");
dict.insert("ğŸ‰");

assert!(dict.contains("cafÃ©"));
assert!(dict.contains("ä¸­æ–‡"));
assert!(dict.contains("ğŸ‰"));

// Remove term
dict.remove("cafÃ©");
assert!(!dict.contains("cafÃ©"));
```

### Example 2: Multi-Language User Dictionary

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

// Create user's personal dictionary
let user_dict = DynamicDawgChar::new();

// User adds words in different languages
user_dict.insert("hello");      // English
user_dict.insert("hola");       // Spanish
user_dict.insert("bonjour");    // French
user_dict.insert("ä½ å¥½");       // Chinese
user_dict.insert("ã“ã‚“ã«ã¡ã¯"); // Japanese
user_dict.insert("Ù…Ø±Ø­Ø¨Ø§");      // Arabic

assert_eq!(user_dict.len(), Some(6));

// User removes a word
user_dict.remove("hola");
assert_eq!(user_dict.len(), Some(5));
```

### Example 3: With Values (Language Codes)

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::dictionary::MappedDictionary;

let dict: DynamicDawgChar<&str> = DynamicDawgChar::new();

// Map terms to language codes
dict.insert_with_value("hello", "en");
dict.insert_with_value("hola", "es");
dict.insert_with_value("bonjour", "fr");
dict.insert_with_value("ä½ å¥½", "zh");
dict.insert_with_value("ã“ã‚“ã«ã¡ã¯", "ja");

// Query language
assert_eq!(dict.get_value("hello"), Some("en"));
assert_eq!(dict.get_value("ä½ å¥½"), Some("zh"));

// Remove and verify
dict.remove("hola");
assert_eq!(dict.get_value("hola"), None);
```

### Example 4: Fuzzy Matching with Unicode

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use liblevenshtein::levenshtein::Algorithm;
use liblevenshtein::levenshtein_automaton::LevenshteinAutomaton;

let dict = DynamicDawgChar::from_terms(vec![
    "cafÃ©", "naÃ¯ve", "rÃ©sumÃ©", "dÃ©jÃ "
]);

// Fuzzy search for "cafe" (missing accent)
let automaton = LevenshteinAutomaton::new("cafe", 1, Algorithm::Standard);
let results: Vec<String> = automaton.query(&dict).collect();

println!("{:?}", results);
// Output: ["cafÃ©"] (distance 1: substitute eâ†’Ã©)

// Add more terms dynamically
dict.insert("cafeteria");

// Search again
let results: Vec<String> = automaton.query(&dict).collect();
println!("{:?}", results);
// Output: ["cafÃ©", "cafeteria"]
```

### Example 5: Emoji Support

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

let dict = DynamicDawgChar::new();

// Insert emoji
dict.insert("ğŸ‰");
dict.insert("ğŸŠ");
dict.insert("ğŸ");
dict.insert("ğŸ˜€");
dict.insert("ğŸ˜ƒ");

// All work correctly
assert!(dict.contains("ğŸ‰"));
assert!(dict.contains("ğŸ˜€"));

// Fuzzy search works
let automaton = LevenshteinAutomaton::new("ğŸ‰", 1, Algorithm::Standard);
let results: Vec<String> = automaton.query(&dict).collect();

// Finds emoji within distance 1
println!("Matches: {}", results.len());
```

### Example 6: CJK Text

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

let dict = DynamicDawgChar::new();

// Chinese
dict.insert("ä¸­æ–‡");
dict.insert("ä¸­å›½");
dict.insert("åŒ—äº¬");

// Japanese
dict.insert("æ—¥æœ¬");
dict.insert("æ±äº¬");

// Korean
dict.insert("í•œêµ­");
dict.insert("ì„œìš¸");

// Fuzzy search in Chinese
let automaton = LevenshteinAutomaton::new("ä¸­æ–‡", 1, Algorithm::Standard);
let results: Vec<String> = automaton.query(&dict).collect();

println!("{:?}", results);
// Finds: ["ä¸­æ–‡", "ä¸­å›½"] (both share "ä¸­")
```

### Example 7: Thread-Safe Updates

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;
use std::sync::Arc;
use std::thread;

let dict = Arc::new(DynamicDawgChar::new());

// Spawn multiple threads adding Unicode terms
let handles: Vec<_> = (0..4).map(|i| {
    let dict = Arc::clone(&dict);
    thread::spawn(move || {
        match i {
            0 => dict.insert("cafÃ©"),
            1 => dict.insert("ä¸­æ–‡"),
            2 => dict.insert("ğŸ˜€"),
            3 => dict.insert("Ù…Ø±Ø­Ø¨Ø§"),
            _ => {}
        }
    })
}).collect();

for handle in handles {
    handle.join().unwrap();
}

// All terms successfully inserted
assert!(dict.contains("cafÃ©"));
assert!(dict.contains("ä¸­æ–‡"));
assert!(dict.contains("ğŸ˜€"));
assert!(dict.contains("Ù…Ø±Ø­Ø¨Ø§"));
```

### Example 8: Compaction with Unicode

```rust
use liblevenshtein::dictionary::dynamic_dawg_char::DynamicDawgChar;

let dict = DynamicDawgChar::from_terms(vec![
    "cafÃ©", "cafÃ©tÃ©ria", "naÃ¯ve", "rÃ©sumÃ©", "dÃ©jÃ "
]);

println!("Before deletion: {} nodes", dict.node_count());

// Remove several terms
dict.remove("cafÃ©");
dict.remove("naÃ¯ve");
dict.remove("dÃ©jÃ ");

println!("After deletion: {} nodes (orphans)", dict.node_count());

// Compact to restore minimality
dict.compact();

println!("After compaction: {} nodes", dict.node_count());
```

## Performance Analysis

### Time Complexity

Same as DynamicDawg:

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| **Insert** | O(m) | m = term length (characters) |
| **Remove** | O(m) | Plus ref count updates |
| **Contains** | O(m) | With Bloom filter: O(1) rejection |
| **Compact** | O(n) | n = total nodes |
| **Query (fuzzy)** | O(mÃ—dÂ²Ã—b) | d = distance, b = branching |

### Benchmark Results

#### Construction

```
Build from 10,000 mixed-script terms:
  DynamicDawgChar:   4.4ms
  DynamicDawg:       4.1ms  (7% faster)
  DoubleArrayTrieChar: 3.4ms (22% faster)
```

#### Runtime Operations

```
Single insertion (Unicode term):
  DynamicDawgChar:  ~840ns
  DynamicDawg:      ~800ns  (5% faster)

Single deletion:
  DynamicDawgChar:  ~1.3Âµs
  DynamicDawg:      ~1.2Âµs  (8% faster)

Contains check (positive):
  DynamicDawgChar:  ~470ns
  DynamicDawg:      ~450ns  (4% faster)
```

#### Fuzzy Search

```
Query "cafÃ©" (distance 2) in 10K-term dict:
  DynamicDawgChar:      44.7Âµs
  DynamicDawg:          42.3Âµs  (5% faster)
  DoubleArrayTrieChar:  17.1Âµs  (62% faster)
```

### Memory Usage

```
10,000-term dictionary (mixed scripts):
  Nodes:          ~490KB
  Suffix cache:   ~32KB
  Bloom filter:   ~12KB
  Total:          ~534KB

vs DynamicDawg:      ~294KB (1.8x smaller)
vs DoubleArrayTrieChar: ~900KB (1.7x larger)
```

### Character-Level vs Byte-Level Trade-offs

```
                        DynamicDawg    DynamicDawgChar    Difference
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Memory per node         25 bytes       49 bytes           +96%
Construction time       4.1ms          4.4ms              +7%
Insert time             800ns          840ns              +5%
Query time              42.3Âµs         44.7Âµs             +6%
Unicode correctness     âŒ             âœ…                 Priceless!
```

**Verdict**: ~2x memory, ~5-8% performance overhead for correct Unicode handling is excellent value.

## When to Use

### Decision Matrix

| Scenario | Recommended | Alternative |
|----------|-------------|-------------|
| **Unicode + dynamic updates** | âœ… DynamicDawgChar | - |
| **Multilingual real-time app** | âœ… DynamicDawgChar | - |
| **ASCII + dynamic updates** | âš ï¸ DynamicDawg | Slightly faster |
| **Unicode + static/append-only** | âš ï¸ DoubleArrayTrieChar | 3x faster |
| **Maximum performance** | âš ï¸ DoubleArrayTrieChar | Fastest |
| **Pure ASCII** | âš ï¸ DynamicDawg | Less memory |

### Ideal Use Cases

1. **Multi-Language User Dictionaries**
   - Users add/remove words in various languages
   - Correct character-level distances crucial
   - Personal vocabularies with emoji, CJK, etc.

2. **Collaborative Editing (International)**
   - Multiple users from different regions
   - Thread-safe concurrent access
   - Full Unicode support needed

3. **Adaptive Spell Checkers**
   - Learn from user corrections
   - Remove obsolete suggestions
   - Handle all scripts correctly

4. **Chat/Messaging Applications**
   - Dynamic emoji/sticker names
   - User-specific vocabularies
   - Multi-language support

5. **Code Completion (International)**
   - Variable names in various scripts
   - Dynamic scope-based filtering
   - Unicode identifier support

## Related Documentation

- [Dictionary Layer](../README.md) - Overview of all dictionary types
- [DynamicDawg](dynamic-dawg.md) - Byte-level variant
- [DoubleArrayTrieChar](double-array-trie-char.md) - Faster static alternative
- [Value Storage](../../09-value-storage/README.md) - Using values with DynamicDawgChar

## References

### Unicode and Levenshtein Distance

1. **Schulz, K. U., & Mihov, S. (2002)**. "Fast String Correction with Levenshtein Automata"
   - *International Journal on Document Analysis and Recognition*, 5(1), 67-85
   - ğŸ“„ Discusses character-level vs byte-level matching

2. **Unicode Consortium**. *The Unicode Standard, Version 15.0*
   - ğŸ“„ [https://www.unicode.org/versions/Unicode15.0.0/](https://www.unicode.org/versions/Unicode15.0.0/)
   - Official Unicode specification

### DAWG Algorithms

3. **Blumer, A., Blumer, J., Haussler, D., McConnell, R., & Ehrenfeucht, A. (1987)**. "Complete inverted files for efficient text retrieval and analysis"
   - *Journal of the ACM*, 34(3), 578-595
   - DOI: [10.1145/28869.28873](https://doi.org/10.1145/28869.28873)
   - ğŸ“„ DAWG construction algorithms

4. **Crochemore, M., & VÃ©rin, R. (1997)**. "Direct construction of compact directed acyclic word graphs"
   - *Annual Symposium on Combinatorial Pattern Matching*, 116-129
   - DOI: [10.1007/3-540-63220-4_55](https://doi.org/10.1007/3-540-63220-4_55)
   - ğŸ“„ Incremental DAWG construction

## Next Steps

- **Byte-Level**: Compare with [DynamicDawg](dynamic-dawg.md)
- **Static Alternative**: Explore [DoubleArrayTrieChar](double-array-trie-char.md)
- **Values**: Learn about [Value Storage](../../09-value-storage/README.md)
- **Unicode Handling**: Read [DoubleArrayTrieChar Unicode Guide](double-array-trie-char.md#unicode-fundamentals)

---

**Navigation**: [â† Dictionary Layer](../README.md) | [DynamicDawg (byte-level)](dynamic-dawg.md) | [Algorithms Home](../../README.md)
